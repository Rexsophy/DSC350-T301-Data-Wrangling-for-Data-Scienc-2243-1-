{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec5d427",
   "metadata": {},
   "source": [
    "#### Rex Gayas DSC350-T301 Data Wrangling for Data Scienc (2243-1)\n",
    "#### Term Project Milestone 2 Winter 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b8533",
   "metadata": {},
   "source": [
    "##### Replace headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26d21aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique ID  Indicator ID                  Name Measure Measure Info  \\\n",
      "0     216498           386            Ozone (O3)    Mean          ppb   \n",
      "1     216499           386            Ozone (O3)    Mean          ppb   \n",
      "2     219969           386            Ozone (O3)    Mean          ppb   \n",
      "3     219970           386            Ozone (O3)    Mean          ppb   \n",
      "4     164876           383  Sulfur Dioxide (SO2)    Mean          ppb   \n",
      "\n",
      "  Geo Type Name  Geo Join ID                    Geo Place Name  \\\n",
      "0            CD          313               Coney Island (CD13)   \n",
      "1            CD          313               Coney Island (CD13)   \n",
      "2       Borough            1                             Bronx   \n",
      "3       Borough            1                             Bronx   \n",
      "4            CD          211  Morris Park and Bronxdale (CD11)   \n",
      "\n",
      "      Time Period  Start Date  Data Value  Message  \n",
      "0     Summer 2013  06/01/2013       34.64      NaN  \n",
      "1     Summer 2014  06/01/2014       33.22      NaN  \n",
      "2     Summer 2013  06/01/2013       31.25      NaN  \n",
      "3     Summer 2014  06/01/2014       31.15      NaN  \n",
      "4  Winter 2008-09  12/01/2008        5.89      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset \n",
    "df = pd.read_csv(r\"D:\\ALPHA\\Dynamic Folder\\Bellevue\\Winter 2023\\Data Wrangling\\Project\\Datasets\\Air_Quality.csv\")\n",
    "\n",
    "# Name new headers\n",
    "new_headers = [\n",
    "    'Unique ID', 'Indicator ID', 'Name', 'Measure', \n",
    "    'Measure Info', 'Geo Type Name', 'Geo Join ID', \n",
    "    'Geo Place Name', 'Time Period', 'Start Date', \n",
    "    'Data Value', 'Message'\n",
    "]\n",
    "\n",
    "# Replace headers\n",
    "df.columns = new_headers\n",
    "\n",
    "# Display DataFrame to check the new headers\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46ae20",
   "metadata": {},
   "source": [
    "##### Format Data into a More Readable Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5c3fd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique ID  Indicator ID                  Name Measure Measure Info  \\\n",
      "0     216498           386            Ozone (O3)    Mean          ppb   \n",
      "1     216499           386            Ozone (O3)    Mean          ppb   \n",
      "2     219969           386            Ozone (O3)    Mean          ppb   \n",
      "3     219970           386            Ozone (O3)    Mean          ppb   \n",
      "4     164876           383  Sulfur Dioxide (SO2)    Mean          ppb   \n",
      "\n",
      "  Geo Type Name  Geo Join ID                    Geo Place Name  \\\n",
      "0            CD          313               Coney Island (CD13)   \n",
      "1            CD          313               Coney Island (CD13)   \n",
      "2       Borough            1                             Bronx   \n",
      "3       Borough            1                             Bronx   \n",
      "4            CD          211  Morris Park and Bronxdale (CD11)   \n",
      "\n",
      "      Time Period  Start_Date  Data Value  Message  \n",
      "0     Summer 2013  2013-06-01       34.64      NaN  \n",
      "1     Summer 2014  2014-06-01       33.22      NaN  \n",
      "2     Summer 2013  2013-06-01       31.25      NaN  \n",
      "3     Summer 2014  2014-06-01       31.15      NaN  \n",
      "4  Winter 2008-09  2008-12-01        5.89      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset \n",
    "df = pd.read_csv(r\"D:\\ALPHA\\Dynamic Folder\\Bellevue\\Winter 2023\\Data Wrangling\\Project\\Datasets\\Air_Quality.csv\")\n",
    "\n",
    "# Format 'Start_Date' to standard date format 'Year-Month-Day'\n",
    "df['Start_Date'] = pd.to_datetime(df['Start_Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Check first few rows to verify \n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc558951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unique ID', 'Indicator ID', 'Name', 'Measure', 'Measure Info',\n",
      "       'Geo Type Name', 'Geo Join ID', 'Geo Place Name', 'Time Period',\n",
      "       'Start_Date', 'Data Value', 'Message'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset \n",
    "df = pd.read_csv(r\"D:\\ALPHA\\Dynamic Folder\\Bellevue\\Winter 2023\\Data Wrangling\\Project\\Datasets\\Air_Quality.csv\")\n",
    "\n",
    "# Print out the current column names to verify\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0b1118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2013-06-01\n",
      "1    2014-06-01\n",
      "2    2013-06-01\n",
      "3    2014-06-01\n",
      "4    2008-12-01\n",
      "Name: Start_Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the correct column name from the output of df.columns\n",
    "df['Start_Date'] = pd.to_datetime(df['Start_Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Verify the change\n",
    "print(df['Start_Date'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d85bf",
   "metadata": {},
   "source": [
    "##### Identify Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a09e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers:\n",
      "       Unique ID  Indicator ID  \\\n",
      "22        130355           639   \n",
      "23        130356           639   \n",
      "24        130357           639   \n",
      "25        130358           639   \n",
      "26        130359           639   \n",
      "...          ...           ...   \n",
      "13994     628936           659   \n",
      "13995     628937           659   \n",
      "14012     628954           659   \n",
      "14013     628955           659   \n",
      "14014     628956           659   \n",
      "\n",
      "                                                    Name  \\\n",
      "22                             PM2.5-Attributable Deaths   \n",
      "23                             PM2.5-Attributable Deaths   \n",
      "24                             PM2.5-Attributable Deaths   \n",
      "25                             PM2.5-Attributable Deaths   \n",
      "26                             PM2.5-Attributable Deaths   \n",
      "...                                                  ...   \n",
      "13994  O3-Attributable Asthma Emergency Department Vi...   \n",
      "13995  O3-Attributable Asthma Emergency Department Vi...   \n",
      "14012  O3-Attributable Asthma Emergency Department Vi...   \n",
      "14013  O3-Attributable Asthma Emergency Department Vi...   \n",
      "14014  O3-Attributable Asthma Emergency Department Vi...   \n",
      "\n",
      "                                               Measure        Measure Info  \\\n",
      "22     Estimated Annual Rate - Adults 30 Yrs and Older  per 100,000 adults   \n",
      "23     Estimated Annual Rate - Adults 30 Yrs and Older  per 100,000 adults   \n",
      "24     Estimated Annual Rate - Adults 30 Yrs and Older  per 100,000 adults   \n",
      "25     Estimated Annual Rate - Adults 30 Yrs and Older  per 100,000 adults   \n",
      "26     Estimated Annual Rate - Adults 30 Yrs and Older  per 100,000 adults   \n",
      "...                                                ...                 ...   \n",
      "13994          Estimated Annual Rate- 18 Yrs and Older  per 100,000 adults   \n",
      "13995          Estimated Annual Rate- 18 Yrs and Older  per 100,000 adults   \n",
      "14012          Estimated Annual Rate- 18 Yrs and Older  per 100,000 adults   \n",
      "14013          Estimated Annual Rate- 18 Yrs and Older  per 100,000 adults   \n",
      "14014          Estimated Annual Rate- 18 Yrs and Older  per 100,000 adults   \n",
      "\n",
      "      Geo Type Name  Geo Join ID                        Geo Place Name  \\\n",
      "22            UHF42          101               Kingsbridge - Riverdale   \n",
      "23            UHF42          102                       Northeast Bronx   \n",
      "24            UHF42          103                    Fordham - Bronx Pk   \n",
      "25            UHF42          104                  Pelham - Throgs Neck   \n",
      "26            UHF42          105                      Crotona -Tremont   \n",
      "...             ...          ...                                   ...   \n",
      "13994         UHF42          302  Central Harlem - Morningside Heights   \n",
      "13995         UHF42          303                           East Harlem   \n",
      "14012         UHF42          410                             Rockaways   \n",
      "14013         UHF42          501                         Port Richmond   \n",
      "14014         UHF42          502                Stapleton - St. George   \n",
      "\n",
      "      Time Period  Start_Date  Data Value  Message  \n",
      "22      2005-2007  2005-01-01       117.7      NaN  \n",
      "23      2005-2007  2005-01-01        77.3      NaN  \n",
      "24      2005-2007  2005-01-01        67.3      NaN  \n",
      "25      2005-2007  2005-01-01        73.6      NaN  \n",
      "26      2005-2007  2005-01-01        65.8      NaN  \n",
      "...           ...         ...         ...      ...  \n",
      "13994   2015-2017  2015-01-01       121.4      NaN  \n",
      "13995   2015-2017  2015-01-01       141.5      NaN  \n",
      "14012   2015-2017  2015-01-01        63.0      NaN  \n",
      "14013   2015-2017  2015-01-01        74.6      NaN  \n",
      "14014   2015-2017  2015-01-01        53.8      NaN  \n",
      "\n",
      "[531 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select 'Data Value' as the numeric column to find outliers\n",
    "Q1 = df['Data Value'].quantile(0.25)\n",
    "Q3 = df['Data Value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "outliers_df = df[(df['Data Value'] < lower_bound) | (df['Data Value'] > upper_bound)]\n",
    "non_outliers_df = df[(df['Data Value'] >= lower_bound) & (df['Data Value'] <= upper_bound)]\n",
    "\n",
    "# Display outliers\n",
    "print(\"Outliers:\")\n",
    "print(outliers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c77245",
   "metadata": {},
   "source": [
    "##### Identify and Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4fee46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [Unique ID, Indicator ID, Name, Measure, Measure Info, Geo Type Name, Geo Join ID, Geo Place Name, Time Period, Start_Date, Data Value, Message]\n",
      "Index: []\n",
      "DataFrame shape after removing duplicates: (16122, 12)\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicates based on all columns\n",
    "duplicates = df[df.duplicated()]\n",
    "\n",
    "# Display the duplicates\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)\n",
    "\n",
    "# Remove duplicates while keeping first occurrence\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Verify removal of duplicates by checking shape of the DataFrame\n",
    "print(\"DataFrame shape after removing duplicates:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9354ee3",
   "metadata": {},
   "source": [
    "##### Fix Inconsistent Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a83e430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unique ID', 'Indicator ID', 'Name', 'Measure', 'Measure Info',\n",
      "       'Geo Type Name', 'Geo Join ID', 'Geo Place Name', 'Time Period',\n",
      "       'Start_Date', 'Data Value', 'Message'],\n",
      "      dtype='object')\n",
      "                   Name Measure\n",
      "0            ozone (o3)    mean\n",
      "1            ozone (o3)    mean\n",
      "2            ozone (o3)    mean\n",
      "3            ozone (o3)    mean\n",
      "4  sulfur dioxide (so2)    mean\n"
     ]
    }
   ],
   "source": [
    "# Verify column names\n",
    "print(df.columns)\n",
    "\n",
    "# Convert the 'Name' column to lowercase for consistency\n",
    "df['Name'] = df['Name'].str.lower()\n",
    "\n",
    "# Convert the 'Measure' column to lowercase for consistency\n",
    "df['Measure'] = df['Measure'].str.lower()\n",
    "\n",
    "# Display changes to verify\n",
    "print(df[['Name', 'Measure']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2c2065ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy[speedup] in c:\\users\\rexar\\anaconda3\\lib\\site-packages (0.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: python-levenshtein>=0.12 in c:\\users\\rexar\\anaconda3\\lib\\site-packages (from fuzzywuzzy[speedup]) (0.23.0)\n",
      "Requirement already satisfied: Levenshtein==0.23.0 in c:\\users\\rexar\\anaconda3\\lib\\site-packages (from python-levenshtein>=0.12->fuzzywuzzy[speedup]) (0.23.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in c:\\users\\rexar\\anaconda3\\lib\\site-packages (from Levenshtein==0.23.0->python-levenshtein>=0.12->fuzzywuzzy[speedup]) (3.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\rexar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\rexar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\rexar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\rexar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\rexar\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\rexar\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy[speedup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a16fa9",
   "metadata": {},
   "source": [
    "##### Conduct Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82175758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geo Place Name\n",
      "Staten Island    6230\n",
      "Queens           3850\n",
      "Bronx            3694\n",
      "Manhattan        1366\n",
      "Brooklyn          982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "# Function replacing each entry with the closest match from a list of desired terms\n",
    "def replace_with_closest_match(entry, choices_list):\n",
    "    # If the entry is NaN (missing), don't match it just return\n",
    "    if pd.isna(entry):\n",
    "        return entry\n",
    "    # Otherwise, find the closest match and return\n",
    "    closest_match = process.extractOne(entry, choices_list)\n",
    "    return closest_match[0]\n",
    "\n",
    "# List of standardized terms expected in the 'Geo Place Name' column\n",
    "standard_terms = ['Manhattan', 'Queens', 'Brooklyn', 'Bronx', 'Staten Island']\n",
    "\n",
    "# Fuzzy matching function applied to the 'Geo Place Name' column\n",
    "df['Geo Place Name'] = df['Geo Place Name'].apply(lambda x: replace_with_closest_match(x, standard_terms))\n",
    "\n",
    "# Display the changes to verify\n",
    "print(df['Geo Place Name'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e030f9",
   "metadata": {},
   "source": [
    "##### Add Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "151eedd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data Value Pollutant Level Category\n",
      "0       34.64                     Good\n",
      "1       33.22                     Good\n",
      "2       31.25                     Good\n",
      "3       31.15                     Good\n",
      "4        5.89                     Good\n"
     ]
    }
   ],
   "source": [
    "# Add new column 'Pollutant Level Category' based on 'Data Value'\n",
    "# Function to categorize pollutant levels\n",
    "def categorize_pollutant_level(value):\n",
    "    if pd.isna(value):\n",
    "        return 'Unknown'  # Handling possible NaN values\n",
    "    elif value < 50:\n",
    "        return 'Good'\n",
    "    elif value < 100:\n",
    "        return 'Moderate'\n",
    "    elif value < 150:\n",
    "        return 'Unhealthy for Sensitive Groups'\n",
    "    elif value < 200:\n",
    "        return 'Unhealthy'\n",
    "    elif value < 300:\n",
    "        return 'Very Unhealthy'\n",
    "    else:\n",
    "        return 'Hazardous'\n",
    "\n",
    "# Function applied to 'Data Value' column to create new category column\n",
    "df['Pollutant Level Category'] = df['Data Value'].apply(categorize_pollutant_level)\n",
    "\n",
    "# Display the new column to verify\n",
    "print(df[['Data Value', 'Pollutant Level Category']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a2b37",
   "metadata": {},
   "source": [
    "#### Reference:https://www.kaggle.com/datasets/kaggleprollc/air-quality-data-nyc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
