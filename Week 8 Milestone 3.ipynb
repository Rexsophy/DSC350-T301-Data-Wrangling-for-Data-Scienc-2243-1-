{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f7791d-2c39-4c30-9bb0-1049621aa2e2",
   "metadata": {},
   "source": [
    "#### Rex Gayas DSC350-T301 Data Wrangling for Data Scienc (2243-1)\n",
    "#### Term Project Milestone 04 FEB 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00120df2-433b-47d8-9f06-0f84b11c0e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully!\n",
      "City: New York, AQI: 32\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the API endpoint with New York as the city\n",
    "api_url = \"https://api.waqi.info/feed/newyork/?token=95481362141897eac4f8263ff574654eccfed309\"\n",
    "\n",
    "# Make a GET request to fetch the data\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Parse the JSON response\n",
    "data = response.json()\n",
    "\n",
    "# Check the status of the request\n",
    "if data['status'] == 'ok':\n",
    "    print(\"Data fetched successfully!\")\n",
    "    # Print a summary of the data\n",
    "    city = data['data']['city']['name']\n",
    "    aqi = data['data']['aqi']\n",
    "    print(f\"City: {city}, AQI: {aqi}\")\n",
    "else:\n",
    "    print(\"Failed to fetch data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a19ffa-3abb-453f-9ee0-2d052ff5f1ac",
   "metadata": {},
   "source": [
    "##### Simulate Data Retrieval Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eddb0115-e0f5-4547-9667-9ad3282aa52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     DateTime  AirQualityIndex      City\n",
      "0  2024-01-29 13:21:29.771351               61  New York\n",
      "1  2024-01-30 01:21:29.771351               86  New York\n",
      "2  2024-01-30 13:21:29.771351               39  New York\n",
      "3  2024-01-31 01:21:29.771351              120  New York\n",
      "4  2024-01-31 13:21:29.771351               32  New York\n",
      "5  2024-02-01 01:21:29.771351               82  New York\n",
      "6  2024-02-01 13:21:29.771351              122  New York\n",
      "7  2024-02-02 01:21:29.771351               35  New York\n",
      "8  2024-02-02 13:21:29.771351              124  New York\n",
      "9  2024-02-03 01:21:29.771351               40  New York\n",
      "10 2024-02-03 13:21:29.771351              140  New York\n",
      "11 2024-02-04 01:21:29.771351               65  New York\n",
      "12 2024-02-04 13:21:29.771351               47  New York\n",
      "13 2024-02-05 01:21:29.771351              125  New York\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Simulate data retrieval over the past week, with two data points per day\n",
    "dates = pd.date_range(end=datetime.now(), periods=14, freq='12H')\n",
    "aqi_values = np.random.choice(range(10, 150), size=14)  # Simulated AQI values within a broad range\n",
    "cities = [\"New York\"] * 14  # Simulating data for New York\n",
    "\n",
    "# Create a DataFrame with the simulated data\n",
    "df = pd.DataFrame({\n",
    "    'DateTime': dates,\n",
    "    'AirQualityIndex': aqi_values,\n",
    "    'City': cities\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e56fe-4b56-4724-af95-db6ce2027c95",
   "metadata": {},
   "source": [
    "##### Introduce Simulated Errors and Inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e45ae60-8e84-4d82-8a4d-25dbc228d49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      DateTime  AirQualityIndex      City\n",
      "0   2024-01-29 13:21:29.771351               61  New York\n",
      "1   2024-01-30 01:21:29.771351               86  New York\n",
      "2   2024-01-30 13:21:29.771351               39  New York\n",
      "3   2024-01-31 01:21:29.771351              120  New York\n",
      "4   2024-01-31 13:21:29.771351               32  New York\n",
      "5   2024-02-01 01:21:29.771351              -20  New York\n",
      "6   2024-02-01 13:21:29.771351              122  New York\n",
      "7   2024-02-02 01:21:29.771351               35  new york\n",
      "8          2024-25-02 12:00:00              124  New York\n",
      "9   2024-02-03 01:21:29.771351               40  New York\n",
      "10  2024-02-03 13:21:29.771351              140  New York\n",
      "11  2024-02-04 01:21:29.771351               65  New York\n",
      "12  2024-02-04 13:21:29.771351               47  New York\n",
      "13  2024-02-05 01:21:29.771351              125  New York\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RexAr\\AppData\\Local\\Temp\\ipykernel_3472\\1634321545.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2024-25-02 12:00:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  df.loc[8, 'DateTime'] = \"2024-25-02 12:00:00\"  # Impossible date, to be cleaned later\n"
     ]
    }
   ],
   "source": [
    "# Introduce some simulated errors/inconsistencies in the data\n",
    "df.loc[5, 'AirQualityIndex'] = -20  # Impossible negative AQI value\n",
    "df.loc[7, 'City'] = \"new york\"  # Inconsistent casing\n",
    "df.loc[8, 'DateTime'] = \"2024-25-02 12:00:00\"  # Impossible date, to be cleaned later\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6c006-e1e7-49c7-86d5-ebc30fc7ee81",
   "metadata": {},
   "source": [
    "##### Replace Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8679d53e-be5d-4dfb-9a6e-87cfe3dc1440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                SampleDateTime  AQI_Value  Location\n",
      "0   2024-01-29 13:21:29.771351         61  New York\n",
      "1   2024-01-30 01:21:29.771351         86  New York\n",
      "2   2024-01-30 13:21:29.771351         39  New York\n",
      "3   2024-01-31 01:21:29.771351        120  New York\n",
      "4   2024-01-31 13:21:29.771351         32  New York\n",
      "5   2024-02-01 01:21:29.771351        -20  New York\n",
      "6   2024-02-01 13:21:29.771351        122  New York\n",
      "7   2024-02-02 01:21:29.771351         35  new york\n",
      "8          2024-25-02 12:00:00        124  New York\n",
      "9   2024-02-03 01:21:29.771351         40  New York\n",
      "10  2024-02-03 13:21:29.771351        140  New York\n",
      "11  2024-02-04 01:21:29.771351         65  New York\n",
      "12  2024-02-04 13:21:29.771351         47  New York\n",
      "13  2024-02-05 01:21:29.771351        125  New York\n"
     ]
    }
   ],
   "source": [
    "# Replace Headers\n",
    "df.columns = ['SampleDateTime', 'AQI_Value', 'Location']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e628f6-29f9-4e36-977d-9b1e9d0d59a5",
   "metadata": {},
   "source": [
    "##### Format Data into a More Readable Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ecd360-8d6e-45b2-bfce-ccf9c0c69849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SampleDateTime  AQI_Value  Location\n",
      "0  2024-01-29 13:21:29.771351         61  New York\n",
      "1  2024-01-30 01:21:29.771351         86  New York\n",
      "2  2024-01-30 13:21:29.771351         39  New York\n",
      "3  2024-01-31 01:21:29.771351        120  New York\n",
      "4  2024-01-31 13:21:29.771351         32  New York\n",
      "5  2024-02-01 01:21:29.771351        -20  New York\n",
      "6  2024-02-01 13:21:29.771351        122  New York\n",
      "7  2024-02-02 01:21:29.771351         35  new york\n",
      "8                         NaT        124  New York\n",
      "9  2024-02-03 01:21:29.771351         40  New York\n",
      "10 2024-02-03 13:21:29.771351        140  New York\n",
      "11 2024-02-04 01:21:29.771351         65  New York\n",
      "12 2024-02-04 13:21:29.771351         47  New York\n",
      "13 2024-02-05 01:21:29.771351        125  New York\n"
     ]
    }
   ],
   "source": [
    "# Correct the DateTime format and convert all entries to actual datetime objects\n",
    "df['SampleDateTime'] = pd.to_datetime(df['SampleDateTime'], errors='coerce')  # This will convert errors to NaT\n",
    "\n",
    "# Make sure the AQI_Value column is numeric and handle any non-numeric entries by converting them to NaN\n",
    "df['AQI_Value'] = pd.to_numeric(df['AQI_Value'], errors='coerce')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39088ef8-03b3-497c-bf67-071c376251ea",
   "metadata": {},
   "source": [
    "##### Identify Outliers and Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62b6cdf9-1e56-42c9-b56e-c472c12674f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SampleDateTime  AQI_Value  Location\n",
      "0  2024-01-29 13:21:29.771351         61  New York\n",
      "1  2024-01-30 01:21:29.771351         86  New York\n",
      "2  2024-01-30 13:21:29.771351         39  New York\n",
      "3  2024-01-31 01:21:29.771351        120  New York\n",
      "4  2024-01-31 13:21:29.771351         32  New York\n",
      "6  2024-02-01 13:21:29.771351        122  New York\n",
      "7  2024-02-02 01:21:29.771351         35  new york\n",
      "8                         NaT        124  New York\n",
      "9  2024-02-03 01:21:29.771351         40  New York\n",
      "10 2024-02-03 13:21:29.771351        140  New York\n",
      "11 2024-02-04 01:21:29.771351         65  New York\n",
      "12 2024-02-04 13:21:29.771351         47  New York\n",
      "13 2024-02-05 01:21:29.771351        125  New York\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with negative AQI values which are considered bad data\n",
    "df = df[df['AQI_Value'] >= 0]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee9fe6-34b0-4d0b-b9e9-6efd0be42ce8",
   "metadata": {},
   "source": [
    "##### Find Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f279e99-477c-47e7-b3f8-46831d848958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SampleDateTime  AQI_Value  Location\n",
      "0  2024-01-29 13:21:29.771351         61  New York\n",
      "1  2024-01-30 01:21:29.771351         86  New York\n",
      "2  2024-01-30 13:21:29.771351         39  New York\n",
      "3  2024-01-31 01:21:29.771351        120  New York\n",
      "4  2024-01-31 13:21:29.771351         32  New York\n",
      "6  2024-02-01 13:21:29.771351        122  New York\n",
      "7  2024-02-02 01:21:29.771351         35  new york\n",
      "8                         NaT        124  New York\n",
      "9  2024-02-03 01:21:29.771351         40  New York\n",
      "10 2024-02-03 13:21:29.771351        140  New York\n",
      "11 2024-02-04 01:21:29.771351         65  New York\n",
      "12 2024-02-04 13:21:29.771351         47  New York\n",
      "13 2024-02-05 01:21:29.771351        125  New York\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b575ce4-0e3d-418b-a137-d4f843c8586b",
   "metadata": {},
   "source": [
    "##### Fix Casing or Inconsistent Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3493a0f8-6713-47c7-9daa-5ec9e3ac0d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SampleDateTime  AQI_Value  Location\n",
      "0  2024-01-29 13:21:29.771351         61  New York\n",
      "1  2024-01-30 01:21:29.771351         86  New York\n",
      "2  2024-01-30 13:21:29.771351         39  New York\n",
      "3  2024-01-31 01:21:29.771351        120  New York\n",
      "4  2024-01-31 13:21:29.771351         32  New York\n",
      "6  2024-02-01 13:21:29.771351        122  New York\n",
      "7  2024-02-02 01:21:29.771351         35  New York\n",
      "8                         NaT        124  New York\n",
      "9  2024-02-03 01:21:29.771351         40  New York\n",
      "10 2024-02-03 13:21:29.771351        140  New York\n",
      "11 2024-02-04 01:21:29.771351         65  New York\n",
      "12 2024-02-04 13:21:29.771351         47  New York\n",
      "13 2024-02-05 01:21:29.771351        125  New York\n"
     ]
    }
   ],
   "source": [
    "df['Location'] = df['Location'].str.title()  # Convert city names to title case\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee07429-74dc-45f0-b9c0-eb224837cd7f",
   "metadata": {},
   "source": [
    "##### Conduct Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39523419-1aea-427d-aa3c-e735dd3a5ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SampleDateTime  AQI_Value  Location\n",
      "0  2024-01-29 13:21:29.771351         61  New York\n",
      "1  2024-01-30 01:21:29.771351         86  New York\n",
      "2  2024-01-30 13:21:29.771351         39  New York\n",
      "3  2024-01-31 01:21:29.771351        120  New York\n",
      "4  2024-01-31 13:21:29.771351         32  New York\n",
      "6  2024-02-01 13:21:29.771351        122  New York\n",
      "7  2024-02-02 01:21:29.771351         35  New York\n",
      "8                         NaT        124  New York\n",
      "9  2024-02-03 01:21:29.771351         40  New York\n",
      "10 2024-02-03 13:21:29.771351        140  New York\n",
      "11 2024-02-04 01:21:29.771351         65  New York\n",
      "12 2024-02-04 13:21:29.771351         47  New York\n",
      "13 2024-02-05 01:21:29.771351        125  New York\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "cities = [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
    "df['Location'] = df['Location'].apply(lambda x: process.extractOne(x, cities)[0])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d960b1-6742-4e4f-b141-09f7c2ee1100",
   "metadata": {},
   "source": [
    "##### Add Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60fcb224-86ce-4ca0-a34d-69e6d666a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SampleDateTime  AQI_Value  Location  \\\n",
      "0  2024-01-29 13:21:29.771351         61  New York   \n",
      "1  2024-01-30 01:21:29.771351         86  New York   \n",
      "2  2024-01-30 13:21:29.771351         39  New York   \n",
      "3  2024-01-31 01:21:29.771351        120  New York   \n",
      "4  2024-01-31 13:21:29.771351         32  New York   \n",
      "6  2024-02-01 13:21:29.771351        122  New York   \n",
      "7  2024-02-02 01:21:29.771351         35  New York   \n",
      "8                         NaT        124  New York   \n",
      "9  2024-02-03 01:21:29.771351         40  New York   \n",
      "10 2024-02-03 13:21:29.771351        140  New York   \n",
      "11 2024-02-04 01:21:29.771351         65  New York   \n",
      "12 2024-02-04 13:21:29.771351         47  New York   \n",
      "13 2024-02-05 01:21:29.771351        125  New York   \n",
      "\n",
      "                      AQI_Category  \n",
      "0                         Moderate  \n",
      "1                         Moderate  \n",
      "2                             Good  \n",
      "3   Unhealthy for Sensitive Groups  \n",
      "4                             Good  \n",
      "6   Unhealthy for Sensitive Groups  \n",
      "7                             Good  \n",
      "8   Unhealthy for Sensitive Groups  \n",
      "9                             Good  \n",
      "10  Unhealthy for Sensitive Groups  \n",
      "11                        Moderate  \n",
      "12                            Good  \n",
      "13  Unhealthy for Sensitive Groups  \n"
     ]
    }
   ],
   "source": [
    "def categorize_aqi(aqi):\n",
    "    if aqi <= 50:\n",
    "        return 'Good'\n",
    "    elif aqi <= 100:\n",
    "        return 'Moderate'\n",
    "    elif aqi <= 150:\n",
    "        return 'Unhealthy for Sensitive Groups'\n",
    "    elif aqi <= 200:\n",
    "        return 'Unhealthy'\n",
    "    elif aqi <= 300:\n",
    "        return 'Very Unhealthy'\n",
    "    else:\n",
    "        return 'Hazardous'\n",
    "\n",
    "df['AQI_Category'] = df['AQI_Value'].apply(categorize_aqi)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
