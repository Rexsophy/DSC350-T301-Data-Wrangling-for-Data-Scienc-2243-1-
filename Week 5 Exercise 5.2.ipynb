{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8dd953",
   "metadata": {},
   "source": [
    "## Assignment 5.2\n",
    "Author: Rex Gayas\n",
    "Date: 14 January 2024\n",
    "Modified By: N/A\n",
    "Description: Data Wrangling with Pandas: Merging, Cleaning, Transforming, and Reshaping CSV Data into Long Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8deba973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\faang.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution to Exercise 1\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1a: Read in the CSV files\n",
    "aapl_df = pd.read_csv('D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\aapl.csv')\n",
    "amzn_df = pd.read_csv('D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\amzn.csv')\n",
    "fb_df = pd.read_csv('D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\fb.csv')\n",
    "goog_df = pd.read_csv('D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\goog.csv')\n",
    "nflx_df = pd.read_csv('D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\nflx.csv')\n",
    "\n",
    "# Step 1b: Add a 'ticker' column to each DataFrame\n",
    "aapl_df['ticker'] = 'AAPL'\n",
    "amzn_df['ticker'] = 'AMZN'\n",
    "fb_df['ticker'] = 'FB'\n",
    "goog_df['ticker'] = 'GOOG'\n",
    "nflx_df['ticker'] = 'NFLX'\n",
    "\n",
    "# Step 1c: Append them together into a single DataFrame\n",
    "faang_df = pd.concat([aapl_df, amzn_df, fb_df, goog_df, nflx_df], ignore_index=True)\n",
    "\n",
    "# Step 1d: Save the result in a CSV file called 'faang.csv'\n",
    "faang_csv_path = 'D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\faang.csv'\n",
    "faang_df.to_csv(faang_csv_path, index=False)\n",
    "\n",
    "faang_csv_path  # Returning the path to the saved 'faang.csv' file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26bad036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>102223600</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1170.510010</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>1189.010010</td>\n",
       "      <td>2694500</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>181.580002</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>177.679993</td>\n",
       "      <td>181.419998</td>\n",
       "      <td>18151900</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1066.939941</td>\n",
       "      <td>1045.229980</td>\n",
       "      <td>1048.339966</td>\n",
       "      <td>1065.000000</td>\n",
       "      <td>1237600</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>201.649994</td>\n",
       "      <td>195.419998</td>\n",
       "      <td>196.100006</td>\n",
       "      <td>201.070007</td>\n",
       "      <td>10966900</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date         high          low         open        close  \\\n",
       "0    2018-01-02    43.075001    42.314999    42.540001    43.064999   \n",
       "251  2018-01-02  1190.000000  1170.510010  1172.000000  1189.010010   \n",
       "502  2018-01-02   181.580002   177.550003   177.679993   181.419998   \n",
       "753  2018-01-02  1066.939941  1045.229980  1048.339966  1065.000000   \n",
       "1004 2018-01-02   201.649994   195.419998   196.100006   201.070007   \n",
       "\n",
       "         volume ticker  \n",
       "0     102223600   AAPL  \n",
       "251     2694500   AMZN  \n",
       "502    18151900     FB  \n",
       "753     1237600   GOOG  \n",
       "1004   10966900   NFLX  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution to Exercise 2\n",
    "\n",
    "# Read the saved 'faang.csv' file\n",
    "faang_df = pd.read_csv('D:\\\\ALPHA\\\\Dynamic Folder\\\\Bellevue\\\\Winter 2023\\\\Data Wrangling\\\\Week 5\\\\faang.csv')\n",
    "\n",
    "# Convert the 'date' column to datetime\n",
    "faang_df['date'] = pd.to_datetime(faang_df['date'])\n",
    "\n",
    "# Convert the 'volume' column to integers\n",
    "faang_df['volume'] = faang_df['volume'].astype(int)\n",
    "\n",
    "# Sort the DataFrame by 'date' and 'ticker'\n",
    "faang_df_sorted = faang_df.sort_values(by=['date', 'ticker'])\n",
    "\n",
    "# Display the sorted DataFrame to verify\n",
    "faang_df_sorted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cede2d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1100.020020</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1102.890015</td>\n",
       "      <td>679000</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>1037.589966</td>\n",
       "      <td>1022.398987</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1023.880005</td>\n",
       "      <td>691500</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>1080.469971</td>\n",
       "      <td>1066.150024</td>\n",
       "      <td>1079.000000</td>\n",
       "      <td>1079.239990</td>\n",
       "      <td>766800</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>1159.589966</td>\n",
       "      <td>1149.589966</td>\n",
       "      <td>1156.979980</td>\n",
       "      <td>1152.839966</td>\n",
       "      <td>798400</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>1255.541992</td>\n",
       "      <td>1246.010010</td>\n",
       "      <td>1249.900024</td>\n",
       "      <td>1249.099976</td>\n",
       "      <td>848600</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1194.625977</td>\n",
       "      <td>1205.020020</td>\n",
       "      <td>1207.770020</td>\n",
       "      <td>870800</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>1211.839966</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1207.329956</td>\n",
       "      <td>887400</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date         high          low         open        close  volume  \\\n",
       "879 2018-07-03  1135.819946  1100.020020  1135.819946  1102.890015  679000   \n",
       "979 2018-11-23  1037.589966  1022.398987  1030.000000  1023.880005  691500   \n",
       "852 2018-05-24  1080.469971  1066.150024  1079.000000  1079.239990  766800   \n",
       "883 2018-07-10  1159.589966  1149.589966  1156.979980  1152.839966  798400   \n",
       "905 2018-08-09  1255.541992  1246.010010  1249.900024  1249.099976  848600   \n",
       "912 2018-08-20  1211.000000  1194.625977  1205.020020  1207.770020  870800   \n",
       "914 2018-08-22  1211.839966  1199.000000  1200.000000  1207.329956  887400   \n",
       "\n",
       "    ticker  \n",
       "879   GOOG  \n",
       "979   GOOG  \n",
       "852   GOOG  \n",
       "883   GOOG  \n",
       "905   GOOG  \n",
       "912   GOOG  \n",
       "914   GOOG  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution to Exercise 3\n",
    "\n",
    "# Find the seven rows with the lowest 'volume'\n",
    "lowest_volume_rows = faang_df_sorted.nsmallest(7, 'volume')\n",
    "\n",
    "# Display the seven rows to verify\n",
    "lowest_volume_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d0cbf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>high</td>\n",
       "      <td>43.075001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>high</td>\n",
       "      <td>1190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>FB</td>\n",
       "      <td>high</td>\n",
       "      <td>181.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>high</td>\n",
       "      <td>1066.939941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>high</td>\n",
       "      <td>201.649994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker variable        value\n",
       "0 2018-01-02   AAPL     high    43.075001\n",
       "1 2018-01-02   AMZN     high  1190.000000\n",
       "2 2018-01-02     FB     high   181.580002\n",
       "3 2018-01-02   GOOG     high  1066.939941\n",
       "4 2018-01-02   NFLX     high   201.649994"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution to Exercise 4\n",
    "\n",
    "# Use melt() to convert the DataFrame to long format\n",
    "# 'date' and 'ticker' are our ID variables, and we will melt all the other columns\n",
    "faang_long_format = faang_df_sorted.melt(id_vars=['date', 'ticker'], \n",
    "                                         var_name='variable', \n",
    "                                         value_name='value')\n",
    "\n",
    "# Display the DataFrame in long format to verify\n",
    "faang_long_format.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de28d9b",
   "metadata": {},
   "source": [
    "##### Exercise 5. Suppose we found out that on July 26, 2018, there was a glitch in the data recorded. How should we handle this? Note that there is no coding required for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3124ebb",
   "metadata": {},
   "source": [
    "###### Solution to Exercise 5\n",
    "To address a data glitch on July 26, 2018, one must first define the nature and scope of the anomaly, whether it's missing data, outliers, or incorrect entries. Evaluating the extent of the glitch helps determine its impact on analyses and decide the appropriate remediation strategy. Consultation with data stakeholders is crucial to understand the context and potential implications of the data irregularity. The strategy to rectify the glitch depends on the glitch type; options include removal, correction, imputation, or simply flagging the affected data. Imputation might involve statistical techniques like mean or median substitution or model-based methods if the data is recoverable. If the glitch is isolated and the corrupted data is non-critical, removal might be the simplest solution. \n",
    "\n",
    "Correcting the data requires reliable sources to make sure of the true values. Flagging is essential when data integrity must be preserved for audit trails or when correction is not feasible. Documentation of the issue and the resolution approach is essential for transparency and future reference. Implementing the chosen strategy requires careful execution and subsequent verification to ensure that the data set's integrity is maintained for accurate analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
